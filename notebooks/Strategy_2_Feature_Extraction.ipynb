{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PnpL6yOXolzk","outputId":"42e9ecd7-a8ab-40b6-eb56-86142df12d2a","executionInfo":{"status":"ok","timestamp":1745612320508,"user_tz":300,"elapsed":16521,"user":{"displayName":"Saivvn","userId":"12466765092162365184"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install mtcnn opencv-python-headless torch torchvision imageio[pyav] --quiet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LZgGKIswo99U","outputId":"768de207-4a40-48c2-a270-e9f9198f6941","executionInfo":{"status":"ok","timestamp":1745612415585,"user_tz":300,"elapsed":93897,"user":{"displayName":"Saivvn","userId":"12466765092162365184"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m113.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m35.2/35.2 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import torch\n","import numpy as np\n","import pandas as pd\n","import imageio.v3 as iio\n","from tqdm import tqdm\n","from pathlib import Path\n","from torchvision import models, transforms\n","from mtcnn import MTCNN"],"metadata":{"id":"t0BmuvkTpB37","executionInfo":{"status":"ok","timestamp":1745612446690,"user_tz":300,"elapsed":16747,"user":{"displayName":"Saivvn","userId":"12466765092162365184"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["base_path = Path(\"/content/drive/MyDrive/DeepFake Detection\")\n","video_dir = base_path / \"merged_dataset\"\n","metadata_path = base_path / \"metadata.csv\"\n","output_dir = base_path / \"processed_features/strategy_2\"\n","output_dir.mkdir(parents=True, exist_ok=True)"],"metadata":{"id":"fa42MvXTpHyE","executionInfo":{"status":"ok","timestamp":1745612454393,"user_tz":300,"elapsed":898,"user":{"displayName":"Saivvn","userId":"12466765092162365184"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["metadata_df = pd.read_csv(metadata_path)\n","label_map = {\"FAKE\": \"Fake\", \"REAL\": \"Real\"}\n","metadata_df[\"full_path\"] = metadata_df.apply(lambda row: video_dir / label_map[row[\"label\"]] / row[\"filename\"], axis=1)"],"metadata":{"id":"d1OrFoYJpKoZ","executionInfo":{"status":"ok","timestamp":1745612456738,"user_tz":300,"elapsed":404,"user":{"displayName":"Saivvn","userId":"12466765092162365184"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["face_detector = MTCNN()\n","model = models.resnext50_32x4d(weights=models.ResNeXt50_32X4D_Weights.DEFAULT)\n","model.fc = torch.nn.Identity()\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device).eval()\n","\n","transform = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VDjHuQ6dpOjw","outputId":"850f0c4c-998f-403b-fa23-b404a644d6ff","executionInfo":{"status":"ok","timestamp":1745612461120,"user_tz":300,"elapsed":3706,"user":{"displayName":"Saivvn","userId":"12466765092162365184"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-1a0047aa.pth\" to /root/.cache/torch/hub/checkpoints/resnext50_32x4d-1a0047aa.pth\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95.8M/95.8M [00:01<00:00, 91.8MB/s]\n"]}]},{"cell_type":"code","source":["def sample_frames(frames):\n","    total = len(frames)\n","    if total == 0: return []\n","    if total < 10: return frames\n","    idxs = np.arange(0, total, total // 10)[:10]\n","    return [frames[i] for i in idxs]"],"metadata":{"id":"Fw3GwujbpQ8V","executionInfo":{"status":"ok","timestamp":1745612462812,"user_tz":300,"elapsed":2,"user":{"displayName":"Saivvn","userId":"12466765092162365184"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def extract_frames(video_path):\n","    try:\n","        frames = list(iio.imread(video_path, plugin=\"pyav\"))\n","        return sample_frames(frames)\n","    except Exception as e:\n","        print(f\"ğŸš« Failed reading {video_path.name}: {e}\")\n","        return []"],"metadata":{"id":"VwxgrhLApSkl","executionInfo":{"status":"ok","timestamp":1745612464677,"user_tz":300,"elapsed":6,"user":{"displayName":"Saivvn","userId":"12466765092162365184"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["@torch.no_grad()\n","def get_features(faces):\n","    if len(faces) == 0: return None\n","    tensors = torch.stack([transform(face) for face in faces]).to(device)\n","    features = model(tensors)\n","    return features.mean(dim=0).cpu().numpy()"],"metadata":{"id":"AOOymvuapUrv","executionInfo":{"status":"ok","timestamp":1745612466350,"user_tz":300,"elapsed":8,"user":{"displayName":"Saivvn","userId":"12466765092162365184"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["for _, row in tqdm(metadata_df.iterrows(), total=len(metadata_df), desc=\"Strategy 2\"):\n","    filename = row[\"filename\"]\n","    video_path = row[\"full_path\"]\n","    out_path = output_dir / filename.replace(\".mp4\", \".npy\")\n","\n","    if out_path.exists():\n","        continue\n","\n","    frames = extract_frames(video_path)\n","    if not frames: continue\n","\n","    faces = []\n","    for frame in frames:\n","        res = face_detector.detect_faces(frame)\n","        if res:\n","            x, y, w, h = res[0][\"box\"]\n","            face = frame[y:y+h, x:x+w]\n","            if face.size > 0: faces.append(face)\n","\n","    if not faces: continue\n","    features = get_features(faces)\n","    if features is None: continue\n","\n","    np.save(out_path, features)\n","\n","print(\"\\nâœ… Strategy 2 complete. Features saved as .npy\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g0rdAed2pXaH","outputId":"078b0289-0eeb-48c2-9948-b3c9f64d0eb2","executionInfo":{"status":"ok","timestamp":1745615798257,"user_tz":300,"elapsed":3329988,"user":{"displayName":"Saivvn","userId":"12466765092162365184"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["Strategy 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2538/2538 [55:30<00:00,  1.31s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","âœ… Strategy 2 complete. Features saved as .npy\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}