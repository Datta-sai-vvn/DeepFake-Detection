{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SDVTr0zNqfA_","outputId":"697e9c47-32ec-48d1-929e-1f835255e441","executionInfo":{"status":"ok","timestamp":1745617202399,"user_tz":300,"elapsed":19464,"user":{"displayName":"Sai vvn","userId":"05978291927028787170"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install mtcnn opencv-python-headless torch torchvision imageio[pyav] --quiet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"usB3-I_Jq4Cg","outputId":"b9bf4672-8489-413f-e27c-c77f6f7d3c53","executionInfo":{"status":"ok","timestamp":1745617321671,"user_tz":300,"elapsed":101691,"user":{"displayName":"Sai vvn","userId":"05978291927028787170"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m119.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m35.2/35.2 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import torch\n","import numpy as np\n","import pandas as pd\n","import imageio.v3 as iio\n","from tqdm import tqdm\n","from pathlib import Path\n","from torchvision import models, transforms\n","from mtcnn import MTCNN"],"metadata":{"id":"Dne4RBSkq_T1","executionInfo":{"status":"ok","timestamp":1745617346866,"user_tz":300,"elapsed":22412,"user":{"displayName":"Sai vvn","userId":"05978291927028787170"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["base_path = Path(\"/content/drive/MyDrive/DeepFake Detection\")\n","video_dir = base_path / \"merged_dataset\"\n","metadata_path = base_path / \"metadata.csv\"\n","output_dir = base_path / \"processed_features/strategy_3\"\n","output_dir.mkdir(parents=True, exist_ok=True)"],"metadata":{"id":"39XThOt5q_5v","executionInfo":{"status":"ok","timestamp":1745617349100,"user_tz":300,"elapsed":774,"user":{"displayName":"Sai vvn","userId":"05978291927028787170"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["metadata_df = pd.read_csv(metadata_path)\n","label_map = {\"FAKE\": \"Fake\", \"REAL\": \"Real\"}\n","metadata_df[\"full_path\"] = metadata_df.apply(lambda row: video_dir / label_map[row[\"label\"]] / row[\"filename\"], axis=1)"],"metadata":{"id":"kuv_6RNJrJap","executionInfo":{"status":"ok","timestamp":1745617352787,"user_tz":300,"elapsed":466,"user":{"displayName":"Sai vvn","userId":"05978291927028787170"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["face_detector = MTCNN()\n","model = models.resnext50_32x4d(weights=models.ResNeXt50_32X4D_Weights.DEFAULT)\n","model.fc = torch.nn.Identity()\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device).eval()\n","\n","transform = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wRYH_3lxrLth","outputId":"cd16e90e-91bb-4ec6-fb48-978a5dd039bd","executionInfo":{"status":"ok","timestamp":1745617363719,"user_tz":300,"elapsed":5563,"user":{"displayName":"Sai vvn","userId":"05978291927028787170"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-1a0047aa.pth\" to /root/.cache/torch/hub/checkpoints/resnext50_32x4d-1a0047aa.pth\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95.8M/95.8M [00:01<00:00, 79.2MB/s]\n"]}]},{"cell_type":"code","source":["def sample_frames(frames):\n","    total = len(frames)\n","    if total == 0: return []\n","    if total < 10: return frames\n","    idxs = np.random.choice(range(total), 10, replace=False)\n","    return [frames[i] for i in idxs]"],"metadata":{"id":"COkNNEV7rOti","executionInfo":{"status":"ok","timestamp":1745617367303,"user_tz":300,"elapsed":4,"user":{"displayName":"Sai vvn","userId":"05978291927028787170"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def extract_frames(video_path):\n","    try:\n","        frames = list(iio.imread(video_path, plugin=\"pyav\"))\n","        return sample_frames(frames)\n","    except Exception as e:\n","        print(f\"ğŸš« Failed reading {video_path.name}: {e}\")\n","        return []"],"metadata":{"id":"AWm6aRjnrQw3","executionInfo":{"status":"ok","timestamp":1745617369152,"user_tz":300,"elapsed":4,"user":{"displayName":"Sai vvn","userId":"05978291927028787170"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["@torch.no_grad()\n","def get_features(faces):\n","    if len(faces) == 0: return None\n","    tensors = torch.stack([transform(face) for face in faces]).to(device)\n","    features = model(tensors)\n","    return features.mean(dim=0).cpu().numpy()"],"metadata":{"id":"AcIzF2qYrTZJ","executionInfo":{"status":"ok","timestamp":1745617370989,"user_tz":300,"elapsed":3,"user":{"displayName":"Sai vvn","userId":"05978291927028787170"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Run Strategy 3\n","for _, row in tqdm(metadata_df.iterrows(), total=len(metadata_df), desc=\"Strategy 3\"):\n","    filename = row[\"filename\"]\n","    video_path = row[\"full_path\"]\n","    out_path = output_dir / filename.replace(\".mp4\", \".npy\")\n","\n","    if out_path.exists():\n","        continue\n","\n","    frames = extract_frames(video_path)\n","    if not frames: continue\n","\n","    faces = []\n","    for frame in frames:\n","        res = face_detector.detect_faces(frame)\n","        if res:\n","            x, y, w, h = res[0][\"box\"]\n","            face = frame[y:y+h, x:x+w]\n","            if face.size > 0: faces.append(face)\n","\n","    if not faces: continue\n","    features = get_features(faces)\n","    if features is None: continue\n","\n","    np.save(out_path, features)\n","\n","print(\"\\nâœ… Strategy 3 complete. Features saved as .npy\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QUQQKg7SrVo5","outputId":"7e06b6bd-d1c4-402b-e74c-a9b22eb0980b","executionInfo":{"status":"ok","timestamp":1745631117577,"user_tz":300,"elapsed":1436781,"user":{"displayName":"Sai vvn","userId":"05978291927028787170"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["Strategy 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2538/2538 [3:49:04<00:00,  5.42s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","âœ… Strategy 3 complete. Features saved as .npy\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}